Mondarin (Si et al., 2023), is another method that focuses on the API level by offering an inexpensive API compared to other services. Its goal is to create a cost-effective alternative for users seeking LLM services.
In a recent study by Si et al. (Si et al., 2023), the authors investigate model extraction attacks from a new perspective. Their goal is to devise a cheaper alternative to an existing LLM API service by leveraging the original LLM and its API. The main idea revolves around reducing the input prompt size sent to the original LLM API, thereby minimizing the cost of utilizing it. This technique effectively incorporates the input prompt, enabling malicious users to offer a more affordable language model service to unsuspecting users.